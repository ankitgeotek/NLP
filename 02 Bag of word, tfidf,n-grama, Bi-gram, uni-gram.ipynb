{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. What is Feature Extraction from text? and why we need it?\n",
    "- Lets say u have a textual data to feed to ML Model. eg- Sentiment analysis from the text.\n",
    "- Problem is ML Algo can not understand text it can understand number only. \n",
    "- Process of converting Text into number are called Feature Extraction from text (aka-text_representation or text_vectorisation)\n",
    "\n",
    "\n",
    "### Q. Why is it difficult?\n",
    "- for Image data input is pixles and pixle values are already in number so easy to convert\n",
    "- speach is Web form and amplitude can be found out in periodic interval in number and can be stored in array and used as an input. hence easy to handle.\n",
    "- Lets we have an english sentence \"Hello How are you?\" and we have to find whether sentiment is +ve, +-ve or neutral?  as it is not directly numerical form it is diffcult for ML Model to handel.\n",
    "\n",
    "### Q. What is the core Idea?\n",
    "- Our Goal should be that after converson number should tell the semantic meaning to the text. If Numbers does not represent semetic meaning ML will not perform well.\n",
    "\n",
    "### Q What are the techniques?\n",
    "1.  One Hot Encoding\n",
    "2.  Bag of Words\n",
    "3.  n-grams\n",
    "4.  Tf-idf\n",
    "5.  Custom feature (eg- avg size of words)\n",
    "6.  Word2vec (aka-Embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Terms \n",
    "### 1. Corpus (c)-\n",
    "    Combination all the words in the dataset (including repeatations) eg- I felt happy because I saw the others were happy.  Here corpus= [I, felt, happy, because, I, saw, the, others, were, happy]\n",
    "\n",
    "### 2. Vocabulary (v)-\n",
    "    Unique Words to make the Corpus. Vocabulary= [I, felt, happy, because, saw, the, others, were]\n",
    "### 3. Document (d)-\n",
    "    Lets say we have 30,000 revies of a movie then each review is one document\n",
    "### 4. Word (w)- \n",
    "    Individual word of each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One  Hot Encoding\n",
    "\n",
    "Document   | Text                |\n",
    ":---------|:----------------------|\n",
    "| D1      | People watch campusx  |\n",
    "| D2      | campusx watch campusx |\n",
    "| D3      | People write comment  |\n",
    "| D4     | campusx write comment |\n",
    "\n",
    "\n",
    "\n",
    "Corpus-\n",
    "people watch campusx campusx watch campusx \n",
    "people write comment campusx write comment\n",
    "\n",
    "vocabulary-\n",
    "people watch campusx write comment\n",
    "v=5\n",
    "\n",
    "words\n",
    "\n",
    "\n",
    "one hot encoding tells that convert each words of document in v-dimension vector\n",
    "\n",
    "|Word          |People | Watch | campusx| write| comment|\n",
    ":-------------|:----------------|:-----|:------|:-------|:-----|\n",
    "| people      | 1    |0      |0       |0     |0       | \n",
    "| watch       | 0    |1      |0       |0     |0       | \n",
    "| campusx     | 0    |0      |1       |0     |0       | \n",
    "| write       | 0    |0      |0       |1     |0       | \n",
    "| comment     | 0    |0      |0       |0     |1       | \n",
    "\n",
    "######\n",
    "\n",
    "Document   | Text                |array|\n",
    ":---------|:---------------------|:---|\n",
    "| D1      | People watch campusx  |[ [1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0] ]| \n",
    "| D2      | campusx watch campusx |[ [0,0,1,0,0], [0,1,0,0,0], [0,0,1,0,0] ]| \n",
    "| D3      | People write comment  |[ [1,0,0,0,0], [0,0,0,1,0], [0,0,0,0,1] ]| \n",
    "| D4     | campusx write comment  | [ [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1] ]| \n",
    "| D5     | watch campusx write comment  | [ [0,1,0,0,0],  [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1] ]| \n",
    "###\n",
    "\n",
    "### Pros of OHE-\n",
    "- it is very intutive\n",
    "- easy to implement\n",
    "\n",
    "### Flaws of OHE- \n",
    "- Sparsity( many zeros in the array) these are difficult to handel and it also lead to overfitting\n",
    "- uneven shape of array , ML will works only on the fixed size of array\n",
    "- oov (out of vocabulary problem) testing data may have the new word eg- Hello campusx people\n",
    "- no capturing of semantic meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Word \n",
    "It best perform in Text Classification eg- Spam classification, News Classification\n",
    "\n",
    "(Library- from sklearn.feature_extraction.text import CountVectorizer)\n",
    "\n",
    "\n",
    "Steps-\n",
    "1. Create Vocabulary from corpus\n",
    "2. from ech document check How many time each word came in the document here intution is: in similar docs similar type of words will come in same frequecy. (Here order and context of words in sentence does not matters)\n",
    "\n",
    "Document   | Text                |People | Watch | campusx| write| comment|\n",
    ":---------|:---------------------|:----------------|:-----|:------|:-------|:-----|\n",
    "| D1      | People watch campusx  | 1    |1      |1       |0     |0       | \n",
    "| D2      | campusx watch campusx |0    |1      |2       |0     |0       | \n",
    "| D3      | People write comment  | 1    |0      |0       |1     |1       |  \n",
    "| D4     | campusx write comment  | 0    |0      |1       |1     |1       |  \n",
    "| D5     | watch campusx write comment  | 0    |1      |1       |1     |1       | \n",
    "##\n",
    "\n",
    "Q. How Semantic meaning is captured here?\n",
    "Ans- We are converting each doc in v dimentional vector(5-D in this case)\n",
    "\n",
    "### Problems of One Hot Encoder Solved by Bag of Words\n",
    "- Shape of vector will not change for any input\n",
    "- OOV( out of vocabulary) new words in the testing data will not effect vector\n",
    "- Semantic relation can be captures frequncy of different words\n",
    "\n",
    "### Flaws\n",
    "- Sparsity is still present(difficult to handel and problem of overfitting)\n",
    "- New words are ignored but they may contain usefull informations\n",
    "- Squence and ordering in English contains the meaning, however bag of words ignore order and sequencing.\n",
    "- Big changes by small words can not be handelled by bag of words.\n",
    "eg- V1= \"This is a very good movie.\" and V2=\"This is not a very good Movie\"  by the logic of bag of words these two vectors V1 and V2 should be very close. however they are just opposite sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':['People watch campusx','campusx watch campusx', 'People write comment', 'campusx write comment'], 'Output':[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  Output\n",
       "0   People watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   People write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv= CountVectorizer() #Making object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(df['text']) #fitting and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Printing array formed by bag of words technique\n",
    "#here squence is [campusx,  comment,  people,  watch,  write]\n",
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trasnformimg new data that also has new words\n",
    "cv.transform(['campusx watch and write comment of the campusx']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
